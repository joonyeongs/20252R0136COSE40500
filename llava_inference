from llava.eval.run_llava import eval_model
import argparse


#prompt = "What can you see in the image? Answer in one sentence briefly."
#image_file = "https://llava-vl.github.io/static/images/view.jpg"


def main(args):
    eval_model(args)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', type=str, default="liuhaotian/llava-v1.5-7b", required=True, help='Path to the model')
    parser.add_argument('--model_base', type=str, default=None, help='Base model')
    parser.add_argument('--prompt', type=str, required=True, help='Prompt for the model')
    parser.add_argument('--image_file', type=str, required=True, help='Path to the image file')
    parser.add_argument('--conv_mode', type=str, default=None, help='Conversation mode')
    parser.add_argument('--sep', type=str, default=',', help='Separator')
    parser.add_argument('--temperature', type=float, default=0, help='Temperature for sampling')
    parser.add_argument('--top_p', type=float, default=None, help='Top-p for nucleus sampling')
    parser.add_argument('--num_beams', type=int, default=1, help='Number of beams for beam search')
    parser.add_argument('--max_new_tokens', type=int, default=512, help='Maximum number of new tokens to generate')
    
    args = parser.parse_args()
    main(args)
